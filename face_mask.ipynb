{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face mask",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnnnbmn/Face-mask-Detection/blob/main/face_mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpPmmEMD2nP7",
        "outputId": "9d97c188-de91-43a3-ddd4-4e8628911305"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g7Q72FwKpv6ZgbC_MqnYts9sQuyDSa7JWXj9kYcB4s-uCU_eFY4agc\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5orCaREzwq5",
        "outputId": "0aeef268-a07e-450d-9363-4870e2f88a5e"
      },
      "source": [
        "%cd  ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikijchIV4GXb",
        "outputId": "30d79dc4-18af-4457-f4f9-1dab2bd1c732"
      },
      "source": [
        "# returning to home directory\n",
        "\n",
        "%cd content/drive/MyDrive/New Masks Dataset\n",
        "# setting the directory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/New Masks Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyHr8B1H9sni",
        "outputId": "7bad8fcd-4e08-430c-cf7f-00ab6dca9db3"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " AccVal_acc.png                        LossVal_loss.png        \u001b[0m\u001b[01;34mTrain\u001b[0m/\n",
            " haarcascade_frontalface_default.xml  'New Masks Dataset.h5'   \u001b[01;34mValidation\u001b[0m/\n",
            " helmet_covid.h5                       \u001b[01;34mTest\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VnIXJBn-YKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f78543d-6c4c-4dba-86e2-54eee6f5d32d"
      },
      "source": [
        "# standard useful data preprocessing imports\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# visualization imports\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "# scikit learn for preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# keras imports -CNN\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxWk3oeW1CI1"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCV5Ab8Q1h9K"
      },
      "source": [
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVwzyqaK3SYV"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEmw1FMaETwd"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_8bu8vvBA-q"
      },
      "source": [
        "IMAGE_SIZE = [128, 128]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx4qMXPMBEgK",
        "outputId": "c471ea76-4462-4ed9-a126-d12854049b66"
      },
      "source": [
        "# add preprocessing layer to the front of VGG\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yNRh7ZsBFp2"
      },
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "# useful for getting number of classes\n",
        "folders = ('New Masks Dataset/*')#/content/Face-Mask-Detection/dataset\n",
        "\n",
        "\n",
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "## prediction = Dense(len(folders), activation='softmax')(x)\n",
        "prediction = Dense(2, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhK9-NM9BfNC",
        "outputId": "03a679e2-3b6d-437d-8049-3c9ced060287"
      },
      "source": [
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "# view the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 16386     \n",
            "=================================================================\n",
            "Total params: 14,731,074\n",
            "Trainable params: 16,386\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3xQEcS4O508"
      },
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOHlrnQZP6kp"
      },
      "source": [
        "# image Data Argumentation\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6YaXRD2QGbU",
        "outputId": "e62c39f6-1b04-4a77-8b4b-668e280816c3"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('Train',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')\n",
        "testing_set = test_datagen.flow_from_directory('Test',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 600 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fApRu3RTtT1",
        "outputId": "e5061cc3-0658-4c1d-8b84-42ef128341b5"
      },
      "source": [
        "len(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUK0RdFo39Mb"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U272V5RknYJh",
        "outputId": "41dcceac-b82d-482e-d683-275b86a069c8"
      },
      "source": [
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=training_set,\n",
        "  epochs=5,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  \n",
        ")\n",
        "  #validation_steps=len(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/5\n",
            " 1/10 [==>...........................] - ETA: 2:27 - loss: 0.9129 - accuracy: 0.3750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py:616: UserWarning: The input 7 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 314s 31s/step - loss: 0.6047 - accuracy: 0.7000 - val_loss: 0.4310 - val_accuracy: 0.8250\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 160s 16s/step - loss: 0.3283 - accuracy: 0.8750 - val_loss: 0.2500 - val_accuracy: 0.9100\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 157s 16s/step - loss: 0.2261 - accuracy: 0.9133 - val_loss: 0.1735 - val_accuracy: 0.9317\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 157s 16s/step - loss: 0.1806 - accuracy: 0.9283 - val_loss: 0.0779 - val_accuracy: 0.9467\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 157s 16s/step - loss: 0.1466 - accuracy: 0.9517 - val_loss: 0.0930 - val_accuracy: 0.9533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NJTFQ1VwF9Y"
      },
      "source": [
        "# Importing the libraries\n",
        "from PIL import Image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import json\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "4EeZ-gvvwJ8X",
        "outputId": "c0a31dab-522f-4659-ba8c-15fcb3189e7a"
      },
      "source": [
        "# loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "#plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "#plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bh-P5o2wKJA"
      },
      "source": [
        "# Importing the libraries\n",
        "from PIL import Image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import json\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zTbrh_Z3JNf"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "model = load_model('New Masks Dataset.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL5sCJAD34wm"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbiuhBh7Z1aV"
      },
      "source": [
        "def face_extractor(img):\n",
        "    # Function detects faces and returns the cropped face\n",
        "    # If no face detected, it returns the input image\n",
        "    \n",
        "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "    \n",
        "    if faces is ():\n",
        "        return None\n",
        "    \n",
        "    # Crop all faces found\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "        cropped_face = img[y:y+h+40, x:x+w+40]\n",
        "\n",
        "    return cropped_face"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uqNfVeF8-QM2",
        "outputId": "e9e9c5ee-d601-4ad2-b51e-baf1bdcd8cb6"
      },
      "source": [
        "\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def VideoCapture():\n",
        "  js = Javascript('''\n",
        "    async function create(){\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.setAttribute('playsinline', '');\n",
        "\n",
        "      div.appendChild(video);\n",
        "\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      await video.play();\n",
        "\n",
        "      canvas =  document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      div_out = document.createElement('div');\n",
        "      document.body.appendChild(div_out);\n",
        "      img = document.createElement('img');\n",
        "      div_out.appendChild(img);\n",
        "    }\n",
        "\n",
        "    async function capture(){\n",
        "        return await new Promise(function(resolve, reject){\n",
        "            pendingResolve = resolve;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
        "            pendingResolve(result);\n",
        "        })\n",
        "    }\n",
        "\n",
        "    function showimg(imgb64){\n",
        "        img.src = \"data:image/jpg;base64,\" + imgb64;\n",
        "    }\n",
        "\n",
        "  ''')\n",
        "  display(js)\n",
        "\n",
        "def byte2image(byte):\n",
        "  jpeg = b64decode(byte.split(',')[1])\n",
        "  im = Image.open(io.BytesIO(jpeg))\n",
        "  return np.array(im)\n",
        "\n",
        "def image2byte(image):\n",
        "  image = Image.fromarray(image)\n",
        "  buffer = io.BytesIO()\n",
        "  image.save(buffer, 'jpeg')\n",
        "  buffer.seek(0)\n",
        "  x = b64encode(buffer.read()).decode('utf-8')\n",
        "  return x\n",
        "\n",
        "VideoCapture()\n",
        "eval_js('create()')\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "\n",
        "    byte = eval_js('capture()')\n",
        "    frame = byte2image(byte)\n",
        "    #_, frame = video_capture.read()\n",
        "    #canvas = detect(gray, frame)\n",
        "    #image, face =face_detector(frame)\n",
        "    \n",
        "    face=face_extractor(frame)\n",
        "    if type(face) is np.ndarray:\n",
        "        face = cv2.resize(face, (128, 128))\n",
        "        im = Image.fromarray(face, 'RGB')\n",
        "           #Resizing into 128x128 because we trained the model with this image size.\n",
        "        img_array = np.array(im)\n",
        "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
        "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        \n",
        "        pred2 = model.predict(img_array)\n",
        "        print(pred2)\n",
        "                     \n",
        "        name=\"None matching\"\n",
        "        \n",
        "        if(pred2[0][0]>0.5):\n",
        "          name='mask' \n",
        "        elif(pred2[0][1]>0.5):\n",
        "            name='no mask'\n",
        "          \n",
        "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
        "    else:\n",
        "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
        "    #cv2.imshow('Video', frame)\n",
        "    eval_js('showimg(\"{}\")'.format(image2byte(frame)))\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "#video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function create(){\n",
              "      div = document.createElement('div');\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.setAttribute('playsinline', '');\n",
              "\n",
              "      div.appendChild(video);\n",
              "\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
              "      video.srcObject = stream;\n",
              "\n",
              "      await video.play();\n",
              "\n",
              "      canvas =  document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "\n",
              "      div_out = document.createElement('div');\n",
              "      document.body.appendChild(div_out);\n",
              "      img = document.createElement('img');\n",
              "      div_out.appendChild(img);\n",
              "    }\n",
              "\n",
              "    async function capture(){\n",
              "        return await new Promise(function(resolve, reject){\n",
              "            pendingResolve = resolve;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
              "            pendingResolve(result);\n",
              "        })\n",
              "    }\n",
              "\n",
              "    function showimg(imgb64){\n",
              "        img.src = \"data:image/jpg;base64,\" + imgb64;\n",
              "    }\n",
              "\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[0. 1.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n",
            "[[1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "djqBB-nNXR9V",
        "outputId": "466ae5ee-83be-4d55-ff76-f3d9a6d80b4c"
      },
      "source": [
        "\n",
        "# Doing some Face Recognition with the webcam\n",
        "VideoCapture()\n",
        "eval_js('create()')\n",
        "\n",
        "while True:\n",
        "\n",
        "\n",
        "    byte = eval_js('capture()')\n",
        "    frame = byte2image(byte)\n",
        "    #_, frame = video_capture.read()\n",
        "    #canvas = detect(gray, frame)\n",
        "    #image, face =face_detector(frame)\n",
        "    \n",
        "    face=face_extractor(frame)\n",
        "    if type(face) is np.ndarray:\n",
        "        face = cv2.resize(face, (224, 224))\n",
        "        im = Image.fromarray(face, 'RGB')\n",
        "           #Resizing into 128x128 because we trained the model with this image size.\n",
        "        img_array = np.array(im)\n",
        "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
        "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        \n",
        "        pred = model.predict(img_array)\n",
        "        print(pred)\n",
        "                     \n",
        "        name=\"None matching\"\n",
        "        \n",
        "        if(pred[0][0]>0.5):\n",
        "          name='mask' \n",
        "        elif(pred[0][1]>0.5):\n",
        "            name='no mask'\n",
        "          \n",
        "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
        "    else:\n",
        "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
        "    #cv2.imshow('Video', frame)\n",
        "    eval_js('showimg(\"{}\")'.format(image2byte(frame)))\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "#video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function create(){\n",
              "      div = document.createElement('div');\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.setAttribute('playsinline', '');\n",
              "\n",
              "      div.appendChild(video);\n",
              "\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
              "      video.srcObject = stream;\n",
              "\n",
              "      await video.play();\n",
              "\n",
              "      canvas =  document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "\n",
              "      div_out = document.createElement('div');\n",
              "      document.body.appendChild(div_out);\n",
              "      img = document.createElement('img');\n",
              "      div_out.appendChild(img);\n",
              "    }\n",
              "\n",
              "    async function capture(){\n",
              "        return await new Promise(function(resolve, reject){\n",
              "            pendingResolve = resolve;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
              "            pendingResolve(result);\n",
              "        })\n",
              "    }\n",
              "\n",
              "    function showimg(imgb64){\n",
              "        img.src = \"data:image/jpg;base64,\" + imgb64;\n",
              "    }\n",
              "\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 128, 128, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name='conv2d_1_input'), name='conv2d_1_input', description=\"created by layer 'conv2d_1_input'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-b2b56ab3c073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:425 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer dense_1 is incompatible with the layer: expected axis -1 of input shape to have value 115200 but received input with shape (None, 373248)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA7IjE0M4Jmt"
      },
      "source": [
        "eval_js('create()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc2-An2z4ADm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}